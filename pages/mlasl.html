<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>American Sign Language Detector with Machine Learning</title>
  <link rel="stylesheet" href="./MLasl.css">
  <link rel="stylesheet" href="../assets/css/style.css">

  <style>
    body { margin:0; background:#fff; font-family: sans-serif; }
    canvas { position:fixed; inset:0; z-index:1;  pointer-events: none; }
    html, body {
      height: 100%;
      overflow-y: auto;
    }
    

    /* Header */
    .site-header {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 60px;
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 0 40px;
      background: transparent;
      z-index: 10000;
    }
    .site-header .logo img {
      height: 32px;
    }
    .nav-links {
      display: flex;
      gap: 40px;
    }
    .nav-links a {
      font-family: sans-serif;
      font-size: 14px;
      font-weight: 500;
      text-decoration: none;
      color: #000;
      letter-spacing: 1px;
      transition: opacity 0.2s ease;
    }
    .nav-links a:hover {
      opacity: 0.6;
    }
  </style>
</head>
<body>
  <!-- Header Component -->

  <!-- Header -->
  <header class="site-header">
    <div class="logo">
      <a href="../index.html">
        <img src="../assets/images/logo.jpg" alt="Logo">
      </a>
    </div>
    <nav class="nav-links">
      <a href="about.html">ABOUT ME</a>
      <a href="work.html" class="active">MY WORK</a>
      <a href="rock.html">WHY ROCK</a>
    </nav>
  </header>

  
  <!-- Hero Section -->
  <div class="asl-container">
    <div class="asl-text-section">
      <h1 class="asl-title">
        American Sign Language Detector with Machine Learning
      </h1>

      <h2 class="asl-subtitle">
        Bridging the Gap between Signers and Technology
      </h2>

      <div class="asl-info">
        <p class="asl-main-text asl-info-line">
          <span style="font-weight: 500;">Overview:</span>
          <span class="asl-main-text"> Real-time American Sign Language (ASL) alphabet recognition system that uses machine learning and computer vision to detect hand signs from a webcam.</span>
        </p>

        <p class="asl-main-text asl-info-line">
          <span style="font-weight: 500;">Role:</span>
          <span class="asl-main-text"> Front-End, Back-End, UX/UI Designer</span>
        </p>

        <p class="asl-main-text asl-info-line">
          <span style="font-weight: 500;">Toolkit:</span>
          <span class="asl-main-text"> Python, TensorFlow / Keras, OpenCV, MongoDB Atlas, Docker, Pytest, Black& Flake8, HTML, CSS, JavaScript, Figma</span>
        </p>
      </div>
    </div>

    <div class="asl-image-section">
      <img src="../assets/mlaslpictures/mlaslmain.svg" alt="ASL Demo" class="asl-main-img">
    </div>
  </div>

  <!-- About the Project Section -->
  <div class="asl-about-section">
    <h2 class="asl-title1" style="text-align: center; margin-bottom: 3rem;">
      About the Project
    </h2>

    <div class="asl-about-content">
      <div class="asl-about-img-wrapper">
        <img src="../assets/mlaslpictures/childsigning1.svg" alt="Child Signing" class="asl-about-img">
      </div>

      <div class="asl-about-text">
        <p class="asl-main-text1">
          While typing remains an option in digital spaces like video conferencing platforms,
          signing allows ASL users to express tone, emotion, and nuance more naturally.
        </p>

        <p class="asl-main-text1">
          This tool supports that expressiveness by recognizing hand signs in real time—making
          communication more intuitive and inclusive for ASL users, and taking a meaningful step
          toward bridging the gap between signers and non-signers in digital platforms.
        </p>

        <p class="asl-main-text1">
          The system uses advanced computer vision techniques to detect and interpret ASL alphabet signs,
          enabling more seamless communication between people who sign and those who don't,
          all within digital environments.
        </p>
      </div>
    </div>
  </div>

  <!-- ASL Chart Section -->
  <div class="asl-chart-section">
    <div class="asl-chart-text">
      <p class="asl-main-text1">
        At its core is a Convolutional Neural Network (CNN) built with TensorFlow, trained to
        recognize all 26 letters (A–Z) of the ASL alphabet. The model takes in a hand image,
        predicts the most likely letter, and returns both the predicted label and a confidence score.
        Results are logged in a MongoDB database for historical tracking and analysis.
      </p>
    </div>

    <div class="asl-chart-card">
      <img src="../assets/mlaslpictures/aslchart1.svg" alt="ASL Alphabet Chart" class="asl-chart-img">
    </div>
  </div>

  <!-- Demo Section -->
  <div class="asl-demo-section">
    <h2 class="asl-title1">Demo</h2>

    <video class="asl-demo-video" controls>
      <source src="../assets/mlaslpictures/ML_ASL_demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>

  <!-- What I Did Section -->
  <div class="asl-whatidid-section">
    <h2 class="asl-title1" style="text-align: center; margin-bottom: 3rem;">
      What I Did
    </h2>

    <div class="asl-whatidid-content">
      <div class="asl-whatidid-img-wrapper">
        <img src="../assets/mlaslpictures/meworking.svg" alt="Working on ASL Project" class="asl-whatidid-img">
      </div>

      <ul class="asl-whatidid-list">
        <li>
          Built and trained a CNN model using TensorFlow on over 52,000 images—2,000 hand sign images per letter (A–Z)—captured using my own hand under different lighting and angles to improve real-world accuracy and avoid overfitting.
        </li>
        <li>
          Wrote a Flask backend that receives an input image (from webcam or API), preprocesses it using OpenCV, performs prediction, and saves the result to MongoDB Atlas with a timestamp.
        </li>
        <li>
          Containerized the entire app using Docker and Docker Compose to run the machine learning client, web server, and database together.
        </li>
        <li>
          Implemented unit tests with Pytest and added CI/CD workflows using GitHub Actions to automatically lint, format, and test the code on every push.
        </li>
        <li>
          Ensured clean, readable code using Black and Flake8 for formatting and style checks.
        </li>
        <li>
          Designed and implemented the frontend using HTML, CSS, and JavaScript to make the interface clean, accessible, and easy to use.
        </li>
      </ul>
    </div>
  </div>

  <!-- GitHub Button -->
  <div class="asl-github-button-wrapper">
    <a href="https://github.com/software-students-spring2025/4-containers-something/tree/main" target="_blank" rel="noopener noreferrer" class="asl-github-button">
      View My Github
    </a>
  </div>

</body>
</html>